# ============================================================
# src/preprocessing.py
# Nettoyage et prÃ©paration des donnÃ©es â€” VERSION FINALE
# ============================================================

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import os
import sys

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from utils import afficher_valeurs_manquantes, detecter_outliers_iqr


# ============================================================
# Ã‰TAPE 1 : Charger les donnÃ©es brutes
# ============================================================

def charger_donnees(chemin='../data/raw/data_original.csv'):
    df = pd.read_csv(chemin)
    print(f"âœ… DonnÃ©es chargÃ©es : {df.shape[0]} lignes, {df.shape[1]} colonnes")
    return df


# ============================================================
# Ã‰TAPE 1b : Parser les dates et IP AVANT suppression
# ============================================================

def parser_dates(df):
    """
    Parse RegistrationDate et LastLoginIP AVANT de les supprimer.

    Pourquoi faire Ã§a EN PREMIER ?
    â†’ Si on supprime d'abord, on perd l'information pour toujours !
    â†’ On extrait ce qui est utile, PUIS on supprime la colonne brute

    RegistrationDate â†’ RegYear, RegMonth, RegDay, RegAnciennete
    LastLoginIP      â†’ IP_privee (1=rÃ©seau local, 0=internet)
    """
    df = df.copy()

    # â”€â”€ RegistrationDate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if 'RegistrationDate' in df.columns:

        # Convertir en format date
        # dayfirst=True â†’ prioritÃ© format UK (jour/mois/annÃ©e)
        # errors='coerce' â†’ si format inconnu â†’ NaT (pas de crash)
        df['RegistrationDate'] = pd.to_datetime(
            df['RegistrationDate'],
            format='mixed',    # â† accepte plusieurs formats mÃ©langÃ©s
            dayfirst=True,
            errors='coerce'
        )

        # Extraire des features utiles depuis la date
        df['RegYear']  = df['RegistrationDate'].dt.year
        df['RegMonth'] = df['RegistrationDate'].dt.month
        df['RegDay']   = df['RegistrationDate'].dt.day

        # AnciennetÃ© = nombre de jours depuis l'inscription jusqu'Ã  aujourd'hui
        # â†’ Plus ce chiffre est grand, plus le client est ancien
        aujourd_hui = pd.Timestamp.today()
        df['RegAnciennete'] = (aujourd_hui - df['RegistrationDate']).dt.days

        # Remplir les NaT Ã©ventuels par la mÃ©diane
        for col in ['RegYear', 'RegMonth', 'RegDay', 'RegAnciennete']:
            df[col] = df[col].fillna(df[col].median())

        print("âœ… RegistrationDate â†’ RegYear, RegMonth, RegDay, RegAnciennete crÃ©Ã©es")

    # â”€â”€ LastLoginIP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if 'LastLoginIP' in df.columns:

        # DÃ©tecter si l'IP est privÃ©e (rÃ©seau local) ou publique (internet)
        # IP privÃ©es connues : 192.168.x.x / 10.x.x.x / 172.16.x.x
        # Un client avec IP privÃ©e = connectÃ© depuis le bureau (B2B ?)
        def est_ip_privee(ip):
            if pd.isna(ip):
                return 0
            ip_str = str(ip)
            return int(
                ip_str.startswith('192.168') or
                ip_str.startswith('10.')     or
                ip_str.startswith('172.16')
            )

        df['IP_privee'] = df['LastLoginIP'].apply(est_ip_privee)
        print("âœ… LastLoginIP      â†’ IP_privee crÃ©Ã©e (1=privÃ©e, 0=publique)")

    return df


# ============================================================
# Ã‰TAPE 2 : Supprimer les colonnes inutiles
# ============================================================

def supprimer_colonnes_inutiles(df):
    """
    Supprime les colonnes inutiles ou dangereuses.

    Pourquoi chaque colonne ?
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    CustomerID          â†’ identifiant pur, ne prÃ©dit rien
    NewsletterSubscribedâ†’ toujours 'Yes' = variance nulle
    LastLoginIP         â†’ dÃ©jÃ  transformÃ©e en IP_privee
    RegistrationDate    â†’ dÃ©jÃ  transformÃ©e en RegYear/Month/Day
    ChurnRiskCategory   â†’ DATA LEAKAGE ! calculÃ©e Ã  partir de Churn
                          Si on la garde, le modÃ¨le "triche" car
                          il voit dÃ©jÃ  la rÃ©ponse avant de prÃ©dire
    """
    colonnes_a_supprimer = [
        'CustomerID',
        'NewsletterSubscribed',
        'LastLoginIP',           # remplacÃ©e par IP_privee
        'RegistrationDate',      # remplacÃ©e par RegYear/Month/Day/Anciennete
        'ChurnRiskCategory'      # DATA LEAKAGE â†’ Ã€ SUPPRIMER ABSOLUMENT
    ]

    colonnes_presentes = [col for col in colonnes_a_supprimer if col in df.columns]
    df = df.drop(columns=colonnes_presentes)

    print(f"âœ… Colonnes supprimÃ©es : {colonnes_presentes}")
    print(f"   Colonnes restantes  : {df.shape[1]}")
    return df


# ============================================================
# Ã‰TAPE 3 : Corriger les valeurs aberrantes
# ============================================================

def corriger_valeurs_aberrantes(df):
    """
    Corrige les codes erreurs dÃ©guisÃ©s en chiffres.

    SupportTicketsCount : -1 et 999 â†’ NaN  (valides : 0-15)
    SatisfactionScore   : -1 et 99  â†’ NaN  (valides : 1-5)
    """
    df = df.copy()

    if 'SupportTicketsCount' in df.columns:
        nb = df['SupportTicketsCount'].isin([-1, 999]).sum()
        df.loc[df['SupportTicketsCount'].isin([-1, 999]), 'SupportTicketsCount'] = np.nan
        print(f"âœ… SupportTicketsCount : {nb} valeurs aberrantes â†’ NaN")

    if 'SatisfactionScore' in df.columns:
        nb = df['SatisfactionScore'].isin([-1, 99]).sum()
        df.loc[df['SatisfactionScore'].isin([-1, 99]), 'SatisfactionScore'] = np.nan
        print(f"âœ… SatisfactionScore   : {nb} valeurs aberrantes â†’ NaN")

    return df


# ============================================================
# Ã‰TAPE 4 : Imputer les valeurs manquantes
# ============================================================

def imputer_valeurs_manquantes(df):
    """
    Remplace les NaN par des valeurs estimÃ©es.

    NumÃ©riques  â†’ mÃ©diane (rÃ©sistante aux outliers)
    Texte       â†’ 'Inconnu'
    """
    df = df.copy()

    colonnes_mediane = ['Age', 'SupportTicketsCount', 'SatisfactionScore']

    for col in colonnes_mediane:
        if col in df.columns:
            nb_nan  = df[col].isnull().sum()
            mediane = df[col].median()
            df[col] = df[col].fillna(mediane)
            print(f"âœ… {col} : {nb_nan} NaN â†’ mÃ©diane ({mediane:.1f})")

    colonnes_cat = df.select_dtypes(include=['object', 'string']).columns
    for col in colonnes_cat:
        nb_nan = df[col].isnull().sum()
        if nb_nan > 0:
            df[col] = df[col].fillna('Inconnu')
            print(f"âœ… {col} : {nb_nan} NaN â†’ 'Inconnu'")

    return df


# ============================================================
# Ã‰TAPE 5 : Feature Engineering
# ============================================================

def feature_engineering(df):
    """
    CrÃ©e de nouvelles colonnes utiles Ã  partir des existantes.
    """
    df = df.copy()

    if 'MonetaryTotal' in df.columns and 'Recency' in df.columns:
        df['MonetaryPerDay'] = df['MonetaryTotal'] / (df['Recency'] + 1)
        print("âœ… Feature crÃ©Ã©e : MonetaryPerDay")

    if 'MonetaryTotal' in df.columns and 'Frequency' in df.columns:
        df['AvgBasketValue'] = df['MonetaryTotal'] / (df['Frequency'] + 1)
        print("âœ… Feature crÃ©Ã©e : AvgBasketValue")

    if 'Recency' in df.columns and 'CustomerTenureDays' in df.columns:
        df['TenureRatio'] = df['Recency'] / (df['CustomerTenureDays'] + 1)
        print("âœ… Feature crÃ©Ã©e : TenureRatio")

    if 'CancelledTransactions' in df.columns and 'TotalTransactions' in df.columns:
        df['CancelRatio'] = df['CancelledTransactions'] / (df['TotalTransactions'] + 1)
        print("âœ… Feature crÃ©Ã©e : CancelRatio")

    return df


# ============================================================
# Ã‰TAPE 6 : Encoder les colonnes catÃ©gorielles
# ============================================================

def encoder_colonnes(df):
    """
    Convertit les colonnes texte en nombres.

    3 mÃ©thodes :
    - Ordinal  : colonnes avec ordre logique (Low < Medium < High)
    - Target   : Country â†’ taux de churn moyen par pays (1 colonne)
    - One-Hot  : colonnes sans ordre â†’ colonnes 0/1
    """
    df = df.copy()

    # â”€â”€ ORDINAL ENCODING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    if 'SpendingCategory' in df.columns:
        ordre = ['Low', 'Medium', 'High', 'VIP']
        df['SpendingCategory'] = pd.Categorical(
            df['SpendingCategory'], categories=ordre, ordered=True).codes
        print("âœ… SpendingCategory    â†’ ordinal (0 Ã  3)")

    if 'LoyaltyLevel' in df.columns:
        ordre = ['Inconnu', 'Nouveau', 'Jeune', 'Ã‰tabli', 'Ancien']
        df['LoyaltyLevel'] = pd.Categorical(
            df['LoyaltyLevel'], categories=ordre, ordered=True).codes
        print("âœ… LoyaltyLevel        â†’ ordinal (0 Ã  4)")

    if 'AgeCategory' in df.columns:
        ordre = ['Inconnu', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']
        df['AgeCategory'] = pd.Categorical(
            df['AgeCategory'], categories=ordre, ordered=True).codes
        print("âœ… AgeCategory         â†’ ordinal (0 Ã  6)")

    if 'BasketSizeCategory' in df.columns:
        ordre = ['Inconnu', 'Petit', 'Moyen', 'Grand']
        df['BasketSizeCategory'] = pd.Categorical(
            df['BasketSizeCategory'], categories=ordre, ordered=True).codes
        print("âœ… BasketSizeCategory  â†’ ordinal (0 Ã  3)")

    if 'PreferredTimeOfDay' in df.columns:
        ordre = ['Nuit', 'Matin', 'Midi', 'AprÃ¨s-midi', 'Soir']
        df['PreferredTimeOfDay'] = pd.Categorical(
            df['PreferredTimeOfDay'], categories=ordre, ordered=True).codes
        print("âœ… PreferredTimeOfDay  â†’ ordinal (0 Ã  4)")

    # â”€â”€ TARGET ENCODING pour Country â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 37+ pays â†’ 1 seule colonne numÃ©rique (taux churn moyen)

    if 'Country' in df.columns and 'Churn' in df.columns:
        taux_churn_par_pays = df.groupby('Country')['Churn'].mean()
        df['Country_encoded'] = df['Country'].map(taux_churn_par_pays)
        df = df.drop(columns=['Country'])
        print("âœ… Country             â†’ Target Encoding (taux churn moyen par pays)")
    elif 'Country' in df.columns:
        df = df.drop(columns=['Country'])
        print("âš ï¸  Country supprimÃ©e")

    # â”€â”€ ONE-HOT ENCODING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # dtype=int â†’ 0 et 1 au lieu de True/False

    colonnes_onehot = [
        'CustomerType',
        'FavoriteSeason',
        'Region',
        'WeekendPreference',
        'ProductDiversity',
        'Gender',
        'AccountStatus',
        'RFMSegment'
    ]

    colonnes_presentes = [col for col in colonnes_onehot if col in df.columns]

    if colonnes_presentes:
        df = pd.get_dummies(df, columns=colonnes_presentes,
                            drop_first=False, dtype=int)
        print(f"âœ… One-Hot Encoding    â†’ 0 et 1 (pas True/False)")
        print(f"   Dimensions aprÃ¨s encodage : {df.shape}")

    return df


# ============================================================
# Ã‰TAPE 7 : Normalisation (appelÃ©e APRÃˆS le split train/test)
# ============================================================

def normaliser(X_train, X_test):
    """
    Centre et rÃ©duit les features numÃ©riques (moyenne=0, Ã©cart-type=1).

    âš ï¸ RÃˆGLE ANTI DATA LEAKAGE :
    fit_transform â†’ sur X_train UNIQUEMENT
    transform     â†’ sur X_test  UNIQUEMENT
    """
    scaler = StandardScaler()
    colonnes_num = X_train.select_dtypes(include=[np.number]).columns.tolist()

    X_train = X_train.copy()
    X_test  = X_test.copy()

    X_train[colonnes_num] = scaler.fit_transform(X_train[colonnes_num])
    X_test[colonnes_num]  = scaler.transform(X_test[colonnes_num])

    print(f"âœ… Normalisation sur {len(colonnes_num)} colonnes numÃ©riques")
    return X_train, X_test, scaler


# ============================================================
# PIPELINE PRINCIPALE
# ============================================================

def pipeline_preprocessing(
        chemin_input='../data/raw/data_original.csv',
        chemin_output='../data/processed/data_clean.csv'):

    print("\n" + "=" * 55)
    print("ðŸš€  DÃ‰MARRAGE DU PREPROCESSING")
    print("=" * 55 + "\n")

    # 1. Charger
    df = charger_donnees(chemin_input)

    # 1b. Parser les dates et IP EN PREMIER (avant suppression !)
    print("\n--- Ã‰tape 1b : Parsing RegistrationDate + LastLoginIP ---")
    df = parser_dates(df)

    # 2. Supprimer les colonnes inutiles + ChurnRiskCategory
    print("\n--- Ã‰tape 2 : Suppression des colonnes inutiles ---")
    df = supprimer_colonnes_inutiles(df)

    # 3. Corriger les valeurs aberrantes
    print("\n--- Ã‰tape 3 : Correction des valeurs aberrantes ---")
    df = corriger_valeurs_aberrantes(df)

    # 4. Imputer les valeurs manquantes
    print("\n--- Ã‰tape 4 : Imputation des valeurs manquantes ---")
    df = imputer_valeurs_manquantes(df)

    # 5. Feature Engineering
    print("\n--- Ã‰tape 5 : Feature Engineering ---")
    df = feature_engineering(df)

    # 6. Encoder
    print("\n--- Ã‰tape 6 : Encodage ---")
    df = encoder_colonnes(df)

    # Sauvegarder
    os.makedirs(os.path.dirname(chemin_output), exist_ok=True)
    df.to_csv(chemin_output, index=False)

    print("\n" + "=" * 55)
    print(f"âœ…  Fichier propre sauvegardÃ© : {chemin_output}")
    print(f"   Dimensions finales : {df.shape[0]} lignes Ã— {df.shape[1]} colonnes")
    print("=" * 55)

    return df


if __name__ == "__main__":
    df_propre = pipeline_preprocessing()